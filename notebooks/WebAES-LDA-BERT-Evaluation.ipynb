{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2747c6c0",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1><b>Word Embedding Based Answer Evaluation System for Online Assessments (WebAES)</b></h1>\n",
    "<h3>A smart system to automate the process of answer evaluation in online assessments.</h3>\n",
    "<h5> LDA + BERT Model for WebAES</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff1911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dkjan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# To perform text pre-processing\n",
    "import string\n",
    "\n",
    "# Natural Language Toolkit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set of stopwords in English\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# To load text corpus and pre-trained LDA model\n",
    "from gensim import corpora, models\n",
    "import gensim.downloader as api\n",
    "\n",
    "# To perform sentence encoding using BERT model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# To determine similarity between 2 vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b3b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained and saved LDA model\n",
    "lda_model = models.LdaModel.load('WebAES_LDA_Model.model')\n",
    "\n",
    "\n",
    "# Load text8 corpus and convert to list of documents\n",
    "text8_corpus = api.load('text8')\n",
    "text8_corpus = [doc for doc in text8_corpus]\n",
    "\n",
    "# List containing list of tokens from each document of text8 corpus\n",
    "list_of_list_of_tokens = []\n",
    "\n",
    "# For each document in the text8 corpus\n",
    "for i in range(len(text8_corpus)):\n",
    "    # Remove stopwords from each document\n",
    "    text8_corpus[i] = [w for w in text8_corpus[i] if w not in en_stopwords]\n",
    "    \n",
    "    # Add list of tokens for document to list of list of tokens\n",
    "    list_of_list_of_tokens.append(text8_corpus[i])\n",
    "    \n",
    "dictionary_LDA = corpora.Dictionary(list_of_list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e78782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform text pre-processing operations\n",
    "def preprocess(text):\n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join([w for w in text.split() if not w.lower() in en_stopwords])\n",
    "    \n",
    "    # Split text into list of tokens\n",
    "    text_tokens = text.split()\n",
    "    \n",
    "    # Return list of tokens\n",
    "    return text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ff5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract topic from text\n",
    "def get_topic_prob(text_tokens):\n",
    "    max_prob_topic, max_prob = 0, 0\n",
    "    \n",
    "    # Get topic probabilities for given text using LDA model\n",
    "    topic_probs = lda_model[dictionary_LDA.doc2bow(text_tokens)]\n",
    "    \n",
    "    # Select topic with highest probability\n",
    "    for topic in topic_probs:\n",
    "        topic_index, topic_prob = topic[0], topic[1]\n",
    "        if topic_prob > max_prob:\n",
    "            max_prob = topic_prob\n",
    "            max_prob_topic = topic_index\n",
    "            \n",
    "    # Return topic with max probability and probabilty of that topic\n",
    "    return max_prob_topic, max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48cf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document embeddings for list of documents\n",
    "def get_bert_embeddings(docs):\n",
    "    # Load pre-trained BERT model\n",
    "    BERT_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    \n",
    "    # Encode documents using BERT model\n",
    "    doc_embeddings = BERT_model.encode(docs)\n",
    "    \n",
    "    # Return document embeddings\n",
    "    return doc_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72cb2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine similarity between documents\n",
    "def similarity(doc_embeddings):\n",
    "    # Similarity score based on cosine similarity measure\n",
    "    sim_score = cosine_similarity([doc_embeddings[0]], doc_embeddings[1:])[0][0]\n",
    "    \n",
    "    # Return similarity score\n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3afe3e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to automatically evaluate test\n",
    "def evaluate(expected, response):\n",
    "    # Pre-rpocessing for expected answer\n",
    "    exp_ans_tokens = preprocess(expected)\n",
    "    \n",
    "    # Get topic for expected answer\n",
    "    exp_ans_topic, exp_ans_topic_prob = get_topic_prob(exp_ans_tokens)\n",
    "    \n",
    "    # Pre-processing for student's response\n",
    "    stu_ans_tokens = preprocess(response)\n",
    "    \n",
    "    # Get topic for student's answer\n",
    "    stu_ans_topic, stu_ans_topic_prob = get_topic_prob(stu_ans_tokens)\n",
    "    \n",
    "    # List of documents\n",
    "    docs = [expected, response]\n",
    "    \n",
    "    # Get document embeddings for expected answer and student response\n",
    "    doc_embeddings = get_bert_embeddings(docs)\n",
    "    \n",
    "    # Get similarity score based on documents embeddings\n",
    "    sim_score = similarity(doc_embeddings)\n",
    "    \n",
    "    # Calculate marks iff topics match for expected answer and student's response\n",
    "    if stu_ans_topic==exp_ans_topic:\n",
    "        marks = (stu_ans_topic_prob/exp_ans_topic_prob)*sim_score*10\n",
    "    # If topics do not match, marks are 0\n",
    "    else:\n",
    "        marks = 0\n",
    "        \n",
    "    # Return marks scored\n",
    "    return marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46429f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to start test\n",
    "def take_test(question, max_marks, expected_answer):\n",
    "    # Get student's response\n",
    "    student_response = input('\\n' + question + ' ({} marks)\\n\\n'.format(max_marks))\n",
    "    \n",
    "    # Determine score for student's response\n",
    "    score = round(evaluate(expected_answer, student_response), 2)\n",
    "    \n",
    "    # Display marks scored\n",
    "    print('\\nYou have scored {} marks out of {}.'.format(score, max_marks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d2e790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have scored 10.0 marks out of 10.\n"
     ]
    }
   ],
   "source": [
    "# Sample question\n",
    "question = 'Give PEAS description for medical diagnosis system.'\n",
    "\n",
    "# Maximum marks for question\n",
    "max_marks = 10\n",
    "\n",
    "# Answer expected by faculty\n",
    "expected_answer = '''The performance measure for medical diagnosis system may include the number of patients healed by \n",
    "correctly and accurately diagnosing diseases. For example, the performance measure may be the percentage of cases diagnosed \n",
    "correctly by the system. The environment for a medical diagnosis system includes patients and their vital signs. This \n",
    "environment is fully observable, dynamic and complete. The actuators include display screens and alert systems that send \n",
    "feedback to doctors. Sensors include equipment including medical sensors as well as medical images.'''\n",
    "\n",
    "# Start test and display result\n",
    "take_test(question, max_marks, expected_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
